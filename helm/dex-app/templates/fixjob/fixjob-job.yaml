{{- if and (not .Values.ingress.tls.letsencrypt) .Release.IsUpgrade .Values.fixJob.enabled }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "dex.fixJob" . }}
  namespace: {{ .Release.Namespace | quote }}
  annotations:
    # create hook dependencies in the right order
    "helm.sh/hook-weight": "-1"
    {{- include "dex.fixJobAnnotations" . | nindent 4 }}
    ignore-check.kube-linter.io/no-read-only-root-fs: "kubectl"
  labels:
    app.kubernetes.io/component: {{ include "dex.fixJob" . | quote }}
    {{- include "dex.fixJobSelectorLabels" . | nindent 4 }}
    role: {{ include "dex.fixJobSelector" . | quote }}
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: {{ include "dex.fixJob" . | quote }}
        {{- include "dex.fixJobSelectorLabels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "dex.fixJob" . }}
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: kubectl
        image: "{{ .Values.registry.domain }}/giantswarm/docker-kubectl:latest"
        command:
        - sh
        - -c
        - |
          set -o errexit ; set -o xtrace ; set -o nounset

          # piping stderr to stdout means kubectl's errors are surfaced
          # in the pod's logs.

          # Temporary fix to work around secret type change
          kubectl -n {{ .Release.Namespace }} delete secret {{ include "resource.dex.name" . }}-tls {{ include "resource.dexk8sauth.name" . }} 2>&1

        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
      restartPolicy: Never
  backoffLimit: 4
{{- end }}
